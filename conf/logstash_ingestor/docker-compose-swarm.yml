version: "3.9"
services: 
  ############################################## Zookeeper ##############################################
  zookeeper:
    image: confluentinc/cp-zookeeper:6.1.0
    networks:
      - kafka-backend
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zk-data:/var/lib/zookeeper/data
      - zk-logs:/var/lib/zookeeper/log
    deploy:
      resources:
        limits:
          memory: 150M
        reservations:
          memory: 50M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 50
        window: 120s

  ##################################### Kafka #####################################
  broker:
    image: confluentinc/cp-kafka:6.1.0
    networks: 
      - default 
      - kafka-backend
    ports:
      - 9092:9092
    volumes:
      - kafka-data:/var/lib/kafka/data
      - kafka-logs:/var/lib/kafka/logs
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      #KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      #KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,EXTERNAL_NETWORK:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,EXTERNAL_NETWORK://172.16.50.10:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      # Only log errors to output
      KAFKA_LOG4J_ROOT_LOGLEVEL: ERROR
      # Enable log cleaner
      KAFKA_LOG_CLEANER_ENABLE: 'true'
      # Keep logs for 4 hours
      KAFKA_LOG_RETENTION_HOURS: 4
      # Keep up to 1 gigabytes of logs
      KAFKA_LOG_RETENTION_BYTES: 1000000000
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 500M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 50
        window: 120s 

  ##################################### Logstash ##################################### 
  logstash:
    image: docker.elastic.co/logstash/logstash:7.11.1
    configs:
      #### config ####
      - source: logstash-config
        target: /usr/share/logstash/config/logstash.yml
      #### inputs ####
      - source: logstash-input
        target: /usr/share/logstash/pipeline/logstash.conf
      #### outputs ####
      - source: logstash-output
        target: /usr/share/logstash/pipeline/30-output-kafka.conf
    secrets:
      - logstash-tls-cert
      - logstash-tls-key
    networks:
      - default
      - kafka-backend
    ports:
      - 5044:5044
      - 127.0.0.1:9600:9600
    depends_on: 
      - kafka
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 500M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 50
        window: 120s

secrets:
  logstash-tls-key:
    external: true
  logstash-tls-cert:
    external: true

configs: 
  logstash-config:
    external: true
  logstash-input:
    external: true
  logstash-output:
    external: true

volumes: 
  zk-data:
  zk-logs:
  kafka-data:
  kafka-logs:

networks: 
  kafka-backend: